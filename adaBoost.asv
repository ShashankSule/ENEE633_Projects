%% let's do AdaBoost here! 

K = 10; % Number of boosts! 
[data, y] = loadandfiddle(); % Load data and labels 
traininig = data; % set training set
weights = (1/size(y))*ones(size(y),1);% initialize every point with the same weight
thetas = []; % K x size(training,2) vector to store all the classifiers 
B = []; % store all the constant shift terms (we'll add it later to the classifiers) 
as = []; % K x 1 vector to store all the weights 
sigma = 0.1; % kernel bandwidth
@(x,y) exp(-(norm(x-y)^2)/(2*sigma)) ; %kernel 
% form kernel matrix: we'll need this for evaluation 
for i = 1:n
    for j = 1:n
        XX(i,j) = k(training(i,:), training(j,:)); % calculate k(x_i, x_j) 
    end
end

for i=1:K 
    p = weights/sum(weights); % Renormalized weight vectors
    [theta,b] = WeakClassifier(p, training, y, k); % Module to compute a weak classifier
    phi = (XX')*(y .* soln); % phi 
    F = F + b; % F, aka the classifier values 
    a = 0.5*log((1 - epsilon)/epsilon); % Compute weight 
    weights = weights.*exp(-y.*F); % wn_i+1 = wn_i * exp(-y_n * F(x_n))
    thetas = [thetas; theta']; % put the weak classifier vectors in 
    B = [B; b]; % update the constant terms in the classifier
    as = [as; a]; % update the weight on each classifier
end

% Finally, to compute the
